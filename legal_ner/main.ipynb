{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bvNWqGNOxPi",
        "outputId": "ad6b0961-3f02-4624-a295-0e1170e72d34"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Cloning into 'PoliToHFI-SemEval2023-Task6'...\n",
            "Switched to a new branch 'feat/language_ext'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "branch 'feat/language_ext' set up to track 'origin/feat/language_ext'.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "git clone https://github.com/ssoBAekiL/PoliToHFI-SemEval2023-Task6.git\n",
        "cd PoliToHFI-SemEval2023-Task6\n",
        "git switch feat/language_ext"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRmPnLAWkSx7",
        "outputId": "eb83d75f-f580-4731-a854-799dea9271d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The operation couldn’t be completed. Unable to locate a Java Runtime.\n",
            "Please visit http://www.java.com for information on installing Java.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!apt install python3.10-venv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "jezaKftAkXMM"
      },
      "outputs": [],
      "source": [
        "!python3 -m venv NER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pmkfWQvVkb1F",
        "outputId": "67f8431e-a88c-4b48-93f3-315486919a7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nervaluate==0.1.8\n",
            "  Downloading nervaluate-0.1.8-py3-none-any.whl (24 kB)\n",
            "Collecting numpy==1.21.5\n",
            "  Downloading numpy-1.21.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m48.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit_learn==1.2.1\n",
            "  Downloading scikit_learn-1.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy==3.4.4\n",
            "  Downloading spacy-3.4.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m119.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.64.0\n",
            "  Downloading tqdm-4.64.0-py2.py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 KB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.26.0\n",
            "  Downloading transformers-4.26.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m89.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting threadpoolctl>=2.0.0\n",
            "  Downloading threadpoolctl-3.2.0-py3-none-any.whl (15 kB)\n",
            "Collecting scipy>=1.3.2\n",
            "  Downloading scipy-1.11.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.1.1\n",
            "  Downloading joblib-1.3.2-py3-none-any.whl (302 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.2/302.2 KB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting preshed<3.1.0,>=3.0.2\n",
            "  Downloading preshed-3.0.9-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m156.9/156.9 KB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-legacy<3.1.0,>=3.0.10\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Collecting jinja2\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 KB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wasabi<1.1.0,>=0.9.1\n",
            "  Downloading wasabi-0.10.1-py3-none-any.whl (26 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0\n",
            "  Downloading murmurhash-1.0.10-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2\n",
            "  Downloading cymem-2.0.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typer<0.8.0,>=0.3.0\n",
            "  Downloading typer-0.7.0-py3-none-any.whl (38 kB)\n",
            "Collecting thinc<8.2.0,>=8.1.0\n",
            "  Downloading thinc-8.1.12-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (919 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m919.6/919.6 KB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting srsly<3.0.0,>=2.4.3\n",
            "  Downloading srsly-2.4.8-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (493 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.0/493.0 KB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4\n",
            "  Downloading pydantic-1.10.13-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m116.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-loggers<2.0.0,>=1.0.0\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Collecting requests<3.0.0,>=2.13.0\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 KB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pathy>=0.3.5\n",
            "  Downloading pathy-0.10.3-py3-none-any.whl (48 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 KB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in ./NER/lib/python3.10/site-packages (from spacy==3.4.4->-r PoliToHFI-SemEval2023-Task6/legal_ner/requirements.txt (line 4)) (59.6.0)\n",
            "Collecting langcodes<4.0.0,>=3.2.0\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 KB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smart-open<7.0.0,>=5.2.1\n",
            "  Downloading smart_open-6.4.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging>=20.0\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-extensions\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 KB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m85.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-6.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (705 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m705.5/705.5 KB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex!=2019.12.17\n",
            "  Downloading regex-2023.10.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (773 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m773.9/773.9 KB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m115.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.13.1-py3-none-any.whl (11 kB)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.19.4-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.7/311.7 KB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.42.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.4/65.4 KB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fsspec>=2023.5.0\n",
            "  Downloading fsspec-2023.12.0-py3-none-any.whl (168 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.9/168.9 KB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5\n",
            "  Downloading idna-3.6-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.6/61.6 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
            "  Downloading urllib3-2.1.0-py3-none-any.whl (104 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.6/104.6 KB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17\n",
            "  Downloading certifi-2023.11.17-py3-none-any.whl (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.5/162.5 KB\u001b[0m \u001b[31m22.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
            "  Downloading charset_normalizer-3.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m142.1/142.1 KB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy>=1.3.2\n",
            "  Downloading scipy-1.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/36.4 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m45.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.11.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (36.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.3/36.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting confection<1.0.0,>=0.0.1\n",
            "  Downloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
            "Collecting blis<0.8.0,>=0.7.8\n",
            "  Downloading blis-0.7.11-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting click<9.0.0,>=7.1.1\n",
            "  Downloading click-8.1.7-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.9/97.9 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0\n",
            "  Downloading MarkupSafe-2.1.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Installing collected packages: wasabi, tokenizers, nervaluate, cymem, wheel, urllib3, typing-extensions, tqdm, threadpoolctl, spacy-loggers, spacy-legacy, smart-open, regex, pyyaml, packaging, nvidia-cuda-nvrtc-cu11, numpy, murmurhash, MarkupSafe, langcodes, joblib, idna, fsspec, filelock, click, charset-normalizer, certifi, catalogue, typer, srsly, scipy, requests, pydantic, preshed, nvidia-cuda-runtime-cu11, nvidia-cublas-cu11, jinja2, blis, scikit_learn, pathy, nvidia-cudnn-cu11, huggingface-hub, confection, transformers, torch, thinc, spacy\n",
            "Successfully installed MarkupSafe-2.1.3 blis-0.7.11 catalogue-2.0.10 certifi-2023.11.17 charset-normalizer-3.3.2 click-8.1.7 confection-0.1.4 cymem-2.0.8 filelock-3.13.1 fsspec-2023.12.0 huggingface-hub-0.19.4 idna-3.6 jinja2-3.1.2 joblib-1.3.2 langcodes-3.3.0 murmurhash-1.0.10 nervaluate-0.1.8 numpy-1.21.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 packaging-23.2 pathy-0.10.3 preshed-3.0.9 pydantic-1.10.13 pyyaml-6.0.1 regex-2023.10.3 requests-2.31.0 scikit_learn-1.2.1 scipy-1.10.1 smart-open-6.4.0 spacy-3.4.4 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.1.12 threadpoolctl-3.2.0 tokenizers-0.13.3 torch-1.13.1 tqdm-4.64.0 transformers-4.26.0 typer-0.7.0 typing-extensions-4.8.0 urllib3-2.1.0 wasabi-0.10.1 wheel-0.42.0\n"
          ]
        }
      ],
      "source": [
        "!source NER/bin/activate; pip install -r PoliToHFI-SemEval2023-Task6/legal_ner/requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fC7wG7zYffs"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ZtVec1JPuBz",
        "outputId": "0bed1332-d06b-4ab3-a916-4ddce80b14ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MODEL:  nlpaueb/bert-base-uncased-echr\n",
            "tokenizer_config.json: 100% 48.0/48.0 [00:00<00:00, 229kB/s]\n",
            "config.json: 100% 1.00k/1.00k [00:00<00:00, 5.46MB/s]\n",
            "vocab.txt: 100% 232k/232k [00:00<00:00, 1.71MB/s]\n",
            "pytorch_model.bin: 100% 440M/440M [00:13<00:00, 32.2MB/s]\n",
            "Some weights of the model checkpoint at nlpaueb/bert-base-uncased-echr were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at nlpaueb/bert-base-uncased-echr and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/content/NER/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 10995\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 430\n",
            "  Number of trainable parameters = 108913949\n",
            " 20% 86/430 [23:37<1:30:45, 15.83s/it]***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:04<00:15,  2.17s/it]\u001b[A\n",
            " 33% 3/9 [00:08<00:18,  3.08s/it]\u001b[A\n",
            " 44% 4/9 [00:13<00:17,  3.55s/it]\u001b[A\n",
            " 56% 5/9 [00:17<00:15,  3.83s/it]\u001b[A\n",
            " 67% 6/9 [00:21<00:12,  4.00s/it]\u001b[A\n",
            " 78% 7/9 [00:26<00:08,  4.11s/it]\u001b[A\n",
            " 89% 8/9 [00:30<00:04,  4.20s/it]\u001b[A\n",
            "                                      \n",
            "\u001b[A{'eval_loss': 0.047785110771656036, 'eval_f1-type-match': 0.6289742478140625, 'eval_f1-partial': 0.69961156618552, 'eval_f1-strict': 0.49748237614092206, 'eval_f1-exact': 0.5789095089275715, 'eval_runtime': 46.1483, 'eval_samples_per_second': 23.273, 'eval_steps_per_second': 0.195, 'epoch': 1.0}\n",
            " 20% 86/430 [24:24<1:30:45, 15.83s/it]\n",
            "100% 9/9 [00:41<00:00,  3.41s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to results/all/nlpaueb/bert-base-uncased-echr/checkpoint-86\n",
            "Configuration saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-86/config.json\n",
            "Model weights saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-86/pytorch_model.bin\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " 40% 172/430 [48:06<1:08:16, 15.88s/it]***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:04<00:15,  2.19s/it]\u001b[A\n",
            " 33% 3/9 [00:08<00:18,  3.10s/it]\u001b[A\n",
            " 44% 4/9 [00:13<00:17,  3.57s/it]\u001b[A\n",
            " 56% 5/9 [00:17<00:15,  3.85s/it]\u001b[A\n",
            " 67% 6/9 [00:21<00:12,  4.03s/it]\u001b[A\n",
            " 78% 7/9 [00:26<00:08,  4.14s/it]\u001b[A\n",
            " 89% 8/9 [00:30<00:04,  4.23s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.023725192993879318, 'eval_f1-type-match': 0.8243902434071423, 'eval_f1-partial': 0.8321377326467404, 'eval_f1-strict': 0.7388809177256501, 'eval_f1-exact': 0.7761836436940862, 'eval_runtime': 42.131, 'eval_samples_per_second': 25.492, 'eval_steps_per_second': 0.214, 'epoch': 2.0}\n",
            " 40% 172/430 [48:48<1:08:16, 15.88s/it]\n",
            "100% 9/9 [00:37<00:00,  3.43s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to results/all/nlpaueb/bert-base-uncased-echr/checkpoint-172\n",
            "Configuration saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-172/config.json\n",
            "Model weights saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-172/pytorch_model.bin\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " 60% 258/430 [1:12:30<45:29, 15.87s/it]***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:04<00:15,  2.18s/it]\u001b[A\n",
            " 33% 3/9 [00:08<00:18,  3.09s/it]\u001b[A\n",
            " 44% 4/9 [00:13<00:17,  3.57s/it]\u001b[A\n",
            " 56% 5/9 [00:17<00:15,  3.85s/it]\u001b[A\n",
            " 67% 6/9 [00:21<00:12,  4.02s/it]\u001b[A\n",
            " 78% 7/9 [00:26<00:08,  4.13s/it]\u001b[A\n",
            " 89% 8/9 [00:30<00:04,  4.22s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.018680769950151443, 'eval_f1-type-match': 0.8680863644831699, 'eval_f1-partial': 0.8661638563494817, 'eval_f1-strict': 0.7968056782956515, 'eval_f1-exact': 0.8183969234893811, 'eval_runtime': 41.7524, 'eval_samples_per_second': 25.723, 'eval_steps_per_second': 0.216, 'epoch': 3.0}\n",
            " 60% 258/430 [1:13:12<45:29, 15.87s/it]\n",
            "100% 9/9 [00:36<00:00,  3.42s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to results/all/nlpaueb/bert-base-uncased-echr/checkpoint-258\n",
            "Configuration saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-258/config.json\n",
            "Model weights saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-258/pytorch_model.bin\n",
            "Deleting older checkpoint [results/all/nlpaueb/bert-base-uncased-echr/checkpoint-86] due to args.save_total_limit\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            " 80% 344/430 [1:36:57<22:44, 15.86s/it]***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:04<00:15,  2.18s/it]\u001b[A\n",
            " 33% 3/9 [00:08<00:18,  3.09s/it]\u001b[A\n",
            " 44% 4/9 [00:13<00:17,  3.57s/it]\u001b[A\n",
            " 56% 5/9 [00:17<00:15,  3.85s/it]\u001b[A\n",
            " 67% 6/9 [00:21<00:12,  4.02s/it]\u001b[A\n",
            " 78% 7/9 [00:26<00:08,  4.13s/it]\u001b[A\n",
            " 89% 8/9 [00:30<00:04,  4.22s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.017573535442352295, 'eval_f1-type-match': 0.8920060326837879, 'eval_f1-partial': 0.8822021111151603, 'eval_f1-strict': 0.8184012061377849, 'eval_f1-exact': 0.8355957762735315, 'eval_runtime': 42.0317, 'eval_samples_per_second': 25.552, 'eval_steps_per_second': 0.214, 'epoch': 4.0}\n",
            " 80% 344/430 [1:37:39<22:44, 15.86s/it]\n",
            "100% 9/9 [00:37<00:00,  3.42s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to results/all/nlpaueb/bert-base-uncased-echr/checkpoint-344\n",
            "Configuration saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-344/config.json\n",
            "Model weights saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-344/pytorch_model.bin\n",
            "Deleting older checkpoint [results/all/nlpaueb/bert-base-uncased-echr/checkpoint-172] due to args.save_total_limit\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "100% 430/430 [2:01:22<00:00, 15.87s/it]***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "\n",
            "  0% 0/9 [00:00<?, ?it/s]\u001b[A\n",
            " 22% 2/9 [00:04<00:15,  2.18s/it]\u001b[A\n",
            " 33% 3/9 [00:08<00:18,  3.09s/it]\u001b[A\n",
            " 44% 4/9 [00:13<00:17,  3.56s/it]\u001b[A\n",
            " 56% 5/9 [00:17<00:15,  3.84s/it]\u001b[A\n",
            " 67% 6/9 [00:21<00:12,  4.02s/it]\u001b[A\n",
            " 78% 7/9 [00:26<00:08,  4.13s/it]\u001b[A\n",
            " 89% 8/9 [00:30<00:04,  4.22s/it]\u001b[A\n",
            "                                       \n",
            "\u001b[A{'eval_loss': 0.017253350466489792, 'eval_f1-type-match': 0.9008601172015793, 'eval_f1-partial': 0.8880338006179065, 'eval_f1-strict': 0.8275237659114028, 'eval_f1-exact': 0.844122528549097, 'eval_runtime': 42.5666, 'eval_samples_per_second': 25.231, 'eval_steps_per_second': 0.211, 'epoch': 5.0}\n",
            "100% 430/430 [2:02:05<00:00, 15.87s/it]\n",
            "100% 9/9 [00:37<00:00,  3.42s/it]\u001b[A\n",
            "                                 \u001b[ASaving model checkpoint to results/all/nlpaueb/bert-base-uncased-echr/checkpoint-430\n",
            "Configuration saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-430/config.json\n",
            "Model weights saved in results/all/nlpaueb/bert-base-uncased-echr/checkpoint-430/pytorch_model.bin\n",
            "Deleting older checkpoint [results/all/nlpaueb/bert-base-uncased-echr/checkpoint-258] due to args.save_total_limit\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 7329.9906, 'train_samples_per_second': 7.5, 'train_steps_per_second': 0.059, 'train_loss': 0.08996309679608012, 'epoch': 5.0}\n",
            "100% 430/430 [2:02:09<00:00, 17.05s/it]\n",
            "Saving model checkpoint to results/\n",
            "Configuration saved in results/config.json\n",
            "Model weights saved in results/pytorch_model.bin\n",
            "/content/NER/lib/python3.10/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1074\n",
            "  Batch size = 128\n",
            "100% 9/9 [00:36<00:00,  4.04s/it]\n"
          ]
        }
      ],
      "source": [
        "!source NER/bin/activate; cd PoliToHFI-SemEval2023-Task6/legal_ner/; python3 main.py \\\n",
        "    --ds_train_path data/SPANISH_ALL.json \\\n",
        "    --ds_valid_path data/SPANISH_VALID.json \\\n",
        "    --output_folder results/ \\\n",
        "    --batch 32 \\\n",
        "    --num_epochs 5 \\\n",
        "    --lr 1e-4 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --warmup_ratio 0.06"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp -r PoliToHFI-SemEval2023-Task6/legal_ner/results/all/studio-ousia/mluke-base drive/MyDrive/DNLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!source NER/bin/activate; cd PoliToHFI-SemEval2023-Task6/legal_ner/; python3 inference.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%bash\n",
        "cd PoliToHFI-SemEval2023-Task6/legal_ner/\n",
        "mkdir results\n",
        "cd results\n",
        "mkdir all\n",
        "cd all\n",
        "mkdir MMG\n",
        "cd MMG\n",
        "mkdir xlm-roberta-large-ner-spanish\n",
        "cd ../../\n",
        "mkdir studio-ousia\n",
        "cd studio-ousia\n",
        "mkdir mluke-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/DNLP/mluke-base/checkpoint-1060 PoliToHFI-SemEval2023-Task6/legal_ner/results/all/studio-ousia/mluke-base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!cp -r /content/drive/MyDrive/DNLP/xlm-roberta-large-ner-spanish/checkpoint-1250 PoliToHFI-SemEval2023-Task6/legal_ner/results/all/MMG/xlm-roberta-large-ner-spanish"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
